{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM\n",
        "長谷川\n",
        "- LSTMを用いて文章分類"
      ],
      "metadata": {
        "id": "Se5WcLO0Qosh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## はじめに\n",
        "ランタイムのタイプをGPUに変更しましょう"
      ],
      "metadata": {
        "id": "qrOmSpKtLdub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *data*"
      ],
      "metadata": {
        "id": "Wqdp2UM-QuCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#データのダウンロード\n",
        "!wget https://www.rondhuit.com/download/ldcc-20140209.tar.gz \n",
        "#ファイルの解凍\n",
        "!tar -zxf ldcc-20140209.tar.gz"
      ],
      "metadata": {
        "id": "8yb32hj3Qxsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd text\n",
        "%ls"
      ],
      "metadata": {
        "id": "8ey34QpAQ0A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import linecache\n",
        "\n",
        "# カテゴリを配列で取得\n",
        "categories = [name for name in os.listdir(\"/content/text\") if os.path.isdir(\"/content/text/\" + name)]\n",
        "print(categories)\n",
        "\n",
        "datasets = pd.DataFrame(columns=[\"title\", \"category\"])\n",
        "for cat in categories:\n",
        "    path = \"/content/text/\" + cat + \"/*.txt\"\n",
        "    files = glob(path)\n",
        "    for text_name in files:\n",
        "        title = linecache.getline(text_name, 3)\n",
        "        s = pd.Series([title, cat], index=datasets.columns)\n",
        "        datasets = datasets.append(s, ignore_index=True)\n",
        "\n",
        "# データフレームシャッフル\n",
        "datasets = datasets.sample(frac=1).reset_index(drop=True)\n",
        "datasets.head()"
      ],
      "metadata": {
        "id": "e7JxP-enRGX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(datasets)"
      ],
      "metadata": {
        "id": "Jhmzu17yV8cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 前処理\n",
        "\n",
        "PyTorchでLSTMをする際、食わせるインプットデータは３次元のテンソルある必要があります"
      ],
      "metadata": {
        "id": "IOJ_XYtvSUuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 以下の宣言で行が単語ベクトル、列が単語のインデックスのマトリクスを生成してる感じ\n",
        "embeds = nn.Embedding(10, 6) # (Embedding(単語の合計数, ベクトル次元数))\n",
        "\n",
        "# ３行目の要素を取り出したいならば\n",
        "w1 = torch.tensor([2])\n",
        "print(embeds(w1))\n",
        "\n",
        "# 3行目、5行目、１０行目の要素を取り出したいならば、\n",
        "w2 = torch.tensor([2,4,9])\n",
        "print(embeds(w2))"
      ],
      "metadata": {
        "id": "yK9UoNkZSXEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mecabのインストール\n",
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7"
      ],
      "metadata": {
        "id": "igG_9V9fS2fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import MeCab\n",
        "import re\n",
        "import torch\n",
        "\n",
        "tagger = MeCab.Tagger(\"-Owakati\")\n",
        "\n",
        "def make_wakati(sentence):\n",
        "    # MeCabで分かち書き\n",
        "    sentence = tagger.parse(sentence)\n",
        "    # 半角全角英数字除去\n",
        "    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n",
        "    # 記号もろもろ除去\n",
        "    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n",
        "    # スペースで区切って形態素の配列へ\n",
        "    wakati = sentence.split(\" \")\n",
        "    # 空の要素は削除\n",
        "    wakati = list(filter((\"\").__ne__, wakati))\n",
        "    return wakati\n",
        "\n",
        "# テスト\n",
        "test = \"【人工知能】は「人間」の仕事を奪った\"\n",
        "print(make_wakati(test))\n",
        "\n",
        "# 単語ID辞書を作成する\n",
        "word2index = {}\n",
        "for title in datasets[\"title\"]:\n",
        "    wakati = make_wakati(title)\n",
        "    for word in wakati:\n",
        "        if word in word2index: continue\n",
        "        word2index[word] = len(word2index)\n",
        "print(\"vocab size : \", len(word2index))\n",
        "\n",
        "# 文章を単語IDの系列データに変換\n",
        "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
        "def sentence2index(sentence):\n",
        "    wakati = make_wakati(sentence)\n",
        "    return torch.tensor([word2index[w] for w in wakati], dtype=torch.long)\n",
        "\n",
        "# テスト\n",
        "test = \"例のあのメニューも！ニコニコ超会議のフードコートメニュー14種類紹介（前半）\"\n",
        "print(sentence2index(test))"
      ],
      "metadata": {
        "id": "BGB5VloXSoZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 全単語数を取得\n",
        "VOCAB_SIZE = len(word2index)\n",
        "# 単語のベクトル数\n",
        "EMBEDDING_DIM = 10\n",
        "test = \"ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」\"\n",
        "# 単語IDの系列データに変換\n",
        "inputs = sentence2index(test)\n",
        "# 各単語のベクトルをまとめて取得\n",
        "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
        "sentence_matrix = embeds(inputs)\n",
        "print(sentence_matrix.size())\n",
        "print(sentence_matrix)"
      ],
      "metadata": {
        "id": "OJYYzFpMSshS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_matrix.view(len(sentence_matrix), 1, -1).size()"
      ],
      "metadata": {
        "id": "50cz2L92WcfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *model*\n",
        "PyTorchでLSTMを使う場合、torch.nn.LSTMを使います。"
      ],
      "metadata": {
        "id": "R8_lHjyVWlDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(word2index)\n",
        "EMBEDDING_DIM = 10\n",
        "HIDDEN_DIM = 128\n",
        "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
        "lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM)\n",
        "s1 = \"震災をうけて感じた、大切だと思ったこと\"\n",
        "print(make_wakati(s1))\n",
        "#['震災', 'を', 'うけ', 'て', '感じ', 'た', '大切', 'だ', 'と', '思っ', 'た', 'こと']\n",
        "\n",
        "inputs1 = sentence2index(s1)\n",
        "emb1 = embeds(inputs1)\n",
        "lstm_inputs1 = emb1.view(len(inputs1), 1, -1)\n",
        "out1, out2 = lstm(lstm_inputs1)\n",
        "print(out1)\n",
        "print(out2)"
      ],
      "metadata": {
        "id": "lBPs3gODWfBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Moduleを継承して新しいクラスを作る。決まり文句\n",
        "class LSTMClassifier(nn.Module):\n",
        "    # モデルで使う各ネットワークをコンストラクタで定義\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        # 親クラスのコンストラクタ。決まり文句\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # インプットの単語をベクトル化するために使う\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    # 順伝播処理はforward関数に記載\n",
        "    def forward(self, sentence):\n",
        "        # 文章内の各単語をベクトル化して出力。2次元のテンソル\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
        "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
        "        _, lstm_out = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
        "        tag_space = self.hidden2tag(lstm_out[0].view(-1, self.hidden_dim))\n",
        "        # softmaxに食わせて、確率として表現\n",
        "        tag_scores = self.softmax(tag_space)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "WXUbgYrUWjPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 正解ラベルの変換"
      ],
      "metadata": {
        "id": "TthVrcVQ91v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category2index = {}\n",
        "for cat in categories:\n",
        "    if cat in category2index: continue\n",
        "    category2index[cat] = len(category2index)\n",
        "print(category2index)\n",
        "\n",
        "def category2tensor(cat):\n",
        "    return torch.tensor([category2index[cat]], dtype=torch.long)\n",
        "\n",
        "print(category2tensor(\"it-life-hack\"))"
      ],
      "metadata": {
        "id": "8ZBIoA3d96g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習"
      ],
      "metadata": {
        "id": "jibifRyj-4Yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "# GPUを使う場合は、ここでモデルとデータGPUに転送する\n"
      ],
      "metadata": {
        "id": "JBS6ysSLA57m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "id": "EYgxrNeNGhoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "# 元データを7:3に分ける（7->学習、3->テスト）\n",
        "traindata, testdata = train_test_split(datasets, train_size=0.7)\n",
        "\n",
        "# 単語のベクトル次元数\n",
        "EMBEDDING_DIM = 10\n",
        "# 隠れ層の次元数\n",
        "HIDDEN_DIM = 128\n",
        "# データ全体の単語数\n",
        "VOCAB_SIZE = len(word2index)\n",
        "# 分類先のカテゴリの数\n",
        "TAG_SIZE = len(categories)\n",
        "# モデル宣言\n",
        "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE)\n",
        "#GPUに以降\n",
        "model = model.to(device)\n",
        "# 損失関数はNLLLoss()を使う。LogSoftmaxを使う時はこれを使うらしい。\n",
        "loss_function = nn.NLLLoss()\n",
        "# 最適化の手法はSGDで。lossの減りに時間かかるけど、一旦はこれを使う。\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# 各エポックの合計loss値を格納する\n",
        "losses = []\n",
        "# 100ループ回してみる。（バッチ化とかGPU使ってないので結構時間かかる...）\n",
        "for epoch in range(100):\n",
        "    all_loss = 0\n",
        "    for title, cat in zip(traindata[\"title\"], traindata[\"category\"]):\n",
        "        # モデルが持ってる勾配の情報をリセット\n",
        "        model.zero_grad()\n",
        "        # 文章を単語IDの系列に変換（modelに食わせられる形に変換）\n",
        "        inputs = sentence2index(title)\n",
        "        inputs = inputs.to(device)\n",
        "        # 順伝播の結果を受け取る\n",
        "        out = model(inputs)\n",
        "        # 正解カテゴリをテンソル化\n",
        "        answer = category2tensor(cat)\n",
        "        answer = answer.to(device)\n",
        "        # 正解とのlossを計算\n",
        "        loss = loss_function(out, answer)\n",
        "        # 勾配をセット\n",
        "        loss.backward()\n",
        "        # 逆伝播でパラメータ更新\n",
        "        optimizer.step()\n",
        "        # lossを集計\n",
        "        all_loss += loss.item()\n",
        "    losses.append(all_loss)\n",
        "    print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "id": "hr0anpHT-6Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "r8h80RiG-99t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 予想精度確認"
      ],
      "metadata": {
        "id": "IVt9XnRNNgNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータの母数計算\n",
        "model = model.to(\"cpu\")\n",
        "test_num = len(testdata)\n",
        "# 正解の件数\n",
        "a = 0\n",
        "# 勾配自動計算OFF\n",
        "with torch.no_grad():\n",
        "    for title, category in zip(testdata[\"title\"], testdata[\"category\"]):\n",
        "        # テストデータの予測\n",
        "        inputs = sentence2index(title)\n",
        "        out = model(inputs)\n",
        "\n",
        "        # outの一番大きい要素を予測結果をする\n",
        "        _, predict = torch.max(out, 1)\n",
        "\n",
        "        answer = category2tensor(category)\n",
        "        if predict == answer:\n",
        "            a += 1\n",
        "print(\"predict : \", a / test_num)\n",
        "# predict :  0.6118391323994578"
      ],
      "metadata": {
        "id": "O3eMfOWKNe8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ygAFtScghHpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}